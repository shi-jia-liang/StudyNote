# 特征点检测与匹配
&emsp;&emsp;在**同时定位与建图**(SLAM)、**运动结构恢复**(SfM)、**相机校准**与**图像匹配**、**立体匹配**等几何计算机视觉任务中，首要的任务就是从图像检测出特征点。特征点一般由关键点和描述子组成，关键点是图像中的二维坐标，从不同的光照条件和视角下，这些位置应该是稳定且可复现的。描述子则是用于描述这些关键点的对应的高维特征编码向量，通过局部图像块的特征提取来获得的，要保证在不同图像下，相同特征点的描述是一致的。然而，特征点检测在现实世界的计算机系统中仍然面临着一些挑战，例如光照变化、大视角变化和遮挡等问题，这些都可能导致特征点的丢失或错误匹配。

## 何为角点
![角点示意图](./Img/FeaturePointDetctionAndMatching/CornerPoint.png)  

&emsp;&emsp;角点是图像中某些属性比较突出的像素点。常见的角点有以下几种：
* 灰度梯度的最大值对应的像素点
* 两条直线或者曲线的交点
* 一阶梯度的导数最大值和梯度方向变化率最大的像素点
* 一阶导数值最大，但是二阶导数值为0的像素点

## 何为关键点
&emsp;&emsp;关键点在宏观定义上与角点定义相同。在现实世界图像中，所谓的关键点不再是简单的直线或者曲线的交点。例如，一个圆盘可认为其中心是一个关键点，叶片的尖端是一个关键点。关键点主要属性，即是其在图像中的`[x, y]`坐标。或者额外加入置信度，最终关键点的属性为`[x, y, c]`。

## 何为描述子
&emsp;&emsp;描述子是用来唯一描述关键点的高维编码，可以通过描述子可以区分两个不同的关键点，也可以在不同图像中寻找同一个关键点。好比是每个人的身份证信息，不同的人对应相应的身份号码。

## 何为特征点
&emsp;&emsp;特征点一般由关键点和描述子组成。

## 深度学习
&emsp;&emsp;深度学习主要学习特征点的关键点提取与描述子编码。

## 特征提取轻量网络编码器
* VGG、RepVGG (`RepVGG: Making VGG-style ConvNets Great Again`,`ELoFTR`(CVPR2024)中使用的编码器，让VGG焕发光彩)
* MobileNet
* ResNet-18(ResNet是重型网络，在特征提取方面可能过于冗余，ResNet-18是ResNet系列中较轻量的版本，适合于特征提取任务)

## 特征检测与匹配模型
* 稀疏关键点检测与匹配：SuperPoint、SuperGlue（SG）、LightGlue（LG）
* 半密集（局部全密集特征匹配）关键点检测与匹配：DRC-Net、LoFTR、EfficientLoFTR、四叉树注意力、MatchFormer、AspanFormer、TopicFM
* 全密集关键点检测与匹配：ROMA

## 解码器
* keypointHead
* descriptorHead(参考`LoFTR`类UNet,使用多尺度描述子编码（深层编码维度低，浅层编码维度高），将深度描述子与关键点位置作为浅层描述子先验)

补充：
1. 参考`Focus What Matters`, 对置信度较低的特征点忽视，对置信度较高的特征点重点关注
2. 参考`LiftFeat`（ICRA2025），可能使用深度信息融入描述子。替换更好的Transformer模型。
3. 使用`ALike`, `SP+SG`, `LG`作为教师模型，训练学生模型。

## 损失函数
1. 教师模型输出的伪真实值y与学生模型输出的预测值，特征点作F2损失函数；描述子作负对数似然损失。  
2. **单应性变换**（随机产生的变换，产生模仿视差）前后的图片，主要是对描述子进行损失计算。

主要的输出：关键点位置加置信度（其实也可以做多尺度，但会产生更多训练消耗，看情况而定），深层描述子，中层描述子，浅层描述子

## 评估特征检测模型
* Relative Pose Estimation 相对位姿估计
	* 评估数据集： **MegaDepth** 和 **ScanNet** 。MegaDepth是一个包含196个场景稀疏三维重建的大规模数据集，该数据集面临的主要挑战包括视角范围广、光照条件变化大以及存在重复模式等问题。ScanNet数据集包含1613个序列，每个序列都配有真实深度图和相机位姿。这些图像展示了视角变化和无纹理区域的室内场景。
	* 评价方案：通过计算匹配结果的相对位姿来估计其匹配精度。位姿误差定义旋转角度与平移距离中的最大值（AUC@5°, AUC@10°, AUC@20°）
* Homography Estimation 单应性估计
	* 评估数据集： **HPatches** 。HPatches包含52个在显著光照变化下的序列和56个在视角上表现出较大变化的序列。
	* 评价方案：计算特征点平均重投影误差，并报告在3个不同阈值（AUC@3px, AUC@5px, AUC@10px）
* Visual Localization 视觉定位  
	* 评估数据集： **InLoc** 和 **Aachen v1.1** 。InLoc数据集采集于室内场景，包含大量重复结构和无纹理区域，每张图像均配有深度图。Aachen v1.1 是具有大视角和昼夜光照变化的户外大规模挑战性数据集，其定位任务对匹配方法的鲁棒性要求尤为严苛。
	* 评价方案：使用开源的定位框架HLoc，对位姿误差进行评估，并报告3个不同阈值([0.25m, 2°], [0.5m, 5°], [1.0m, 10°])。InLoc针对`DUC1`、`DUC2`场景；Aachen v1.1针对`Day`、`Night`场景。

## 启发
* 是否可以使用相减获得特征网络层？
* 使用方框滤波器逼近差分特征网络。
* 关键点提取有无更好的办法？

## 阅读SuperGlue受到的启发
1. 使用self-Attation对同一图片的各层特征图融合后进行计算
2. 使用cross-Attation对图像对的各层特征图进行计算

## 特征点检测的有高潜力的研究防线
1. 几何-等变（equivariant）注意力/描述子理论  
	* 要点：设计对平移/旋转/缩放或更一般相机变换（局部SE(2)/SE(3)）等变的 attention 架构或 descriptors，使网络在理论上满足特定群的等变性。
	* 潜力：把“黑箱的注意力”变成带对称性公理的模块，能让后续证明稳定性、泛化性变得可能。
2. 带几何先验的可微最优传输（OT）匹配，附带误差界
	* 要点：把匹配看作约束最优传输问题（图像几何作为正则），设计可微且有近似误差界的求解器（加速 Sinkhorn +几何正则），给出匹配误差/鲁棒性界。
	* 潜力：给出“最优性”形式的理论保证（如在噪声/遮挡下的上界），比单纯经验式的相似度匹配更有理论分量。
3. 概率描述子与联合不确定性匹配（概率嵌入 + 判别界）
	* 要点：每个特征输出为分布（均值+协方差或混合模型），匹配通过最小化统计距离并能给出置信度，证明错误匹配概率界或一致性。
	* 潜力：把“匹配置信度”从经验阈值变成概率论证据，方便理论分析与下游模块（如 RANSAC、PnP）耦合并定量分析。
4. 可证明近似的高效注意力（核化/随机特征）
	* 要点：设计针对视觉匹配的近似 attention（Kernel Attention / Random Feature），并证明在给定图像尺寸和描述子结构下的近似误差界与内存/时间上界。
	* 潜力：给出“在误差不超过 ε 时，内存/计算量为 ...”类理论与工程折衷，是产出论文的好点。
5. 能量式模型与全局一致性证明（global energy with convex relaxations）
	* 要点：把匹配问题构造为能量最小化（含几何/描述子项），研究凸松弛或可证明近似最优的求解器（Lagrangian, SDP relax），给出approximation ratio。
	* 潜力：若能在真实图像匹配上同时给出近似比与实验优越性，理论+实践兼备，容易发表。

## 可选方向
1. 可微 NMS + Soft-Argmax（SoftNMS + subpixel）
	* 意思：用可微的抑制（SoftNMS 或基于分布的抑制）代替硬 NMS，并用局部加权均值/二次拟合在响应图上做亚像素定位（Soft-argmax / quadratic peak fit）。
	* 优点：易集成、训练端可微、能明显提升定位精度与重复性。实现难度低→中。
	* 风险：需要合适数值稳定化（温度、窗大小）。
2. 概率化关键点（输出 mean + covariance）+ 区别阈值决策
	* 意思：每个候选点输出不确定度；匹配和下游（RANSAC）利用置信度加权。
	* 优点：理论可分析（错误率上界），提升鲁棒性。实现难度中→高（需要损失设计）。
	* 风险：训练更复杂，需采样/近似。
3. 局部几何等变检测器（steerable / equivariant detector）
	* 意思：在 detector 结构中加入等变滤波，使检测对旋转/尺度更健壮（可结合 steerable filters）。
	* 优点：对视角/旋转变化提升显著；理论深。实现难度高。
	* 风险：实现复杂、训练难以稳定。
4. Attention-based keypoint pruning（在稠密 score map 上用 self- / cross-attention 选择最稳定点）
	* 意思：用轻量 attention 在候选响应上学习排序/抑制，选择最可匹配点。
	* 优点：能直接优化 matching 目标，灵活。实现难度中。
	* 风险：可能增加计算开销，需要设计稀疏化策略。
5. 可证明一致性的全局选择（能量最小化 + relaxations）
	* 意思：将关键点选择与匹配视作联合能量最小化问题（例如带约束的二次规划），用松弛获得近似解并给出证据。
	* 优点：理论分量足，有望发表理论结果。实现难度很高，计算开销大。
	* 风险：可扩展性与实际效果是主要问题。

## 曾经的失败改进
1. 使用简单的全局位置编码。这样模型在训练过程中会过拟合于训练数据的特定位置分布，导致在测试时对不同位置的特征点检测性能下降。
2. 使用了稀疏注意力机制、Swin Transformer等局部注意力机制。虽然这些方法在某些任务中表现良好，但在特征点检测与匹配任务中，可能会导致模型无法捕捉到全局上下文信息，从而影响特征点的稳定性和匹配的准确性。同时复杂的注意力机制也可能增加模型的计算复杂度，导致训练和推理效率降低，无法满足模型的轻量化、实时性需求。
3. 开启L2归一化，限制了特征表达能力。L2归一化虽然可以使特征向量的长度保持一致，但在某些情况下可能会限制模型的表达能力，导致特征点的描述子无法充分利用其潜在的区分能力，从而影响匹配的准确性。
4. 开启坐标回归损失。坐标回归损失可能会导致模型过于关注特征点的精确位置，而忽略了特征点的描述子信息，从而影响匹配的鲁棒性和准确性。同时，坐标回归损失可能会增加模型的训练难度，导致训练过程不稳定，无法达到预期的性能提升。这与全局位置编码相似。

## 当前的改进
1. 使用更多的高阶几何特征：例如曲率、边界信息等，来增强特征点的描述能力。
2. 自适应几何门控：智能加权。利用几何特征（如曲率、法线方差）生成门控图，动态决定是信任几何形状还是视觉纹理。
3. 局部细化模块：边缘锐化。在 Attention 全局处理后，利用原始几何边界（如 Depth Edge）作为引导，恢复被平滑的高频细节。